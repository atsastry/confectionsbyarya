{"ast":null,"code":"\"use strict\";\n\nvar _objectSpread = require(\"/Users/aryasastry/bootcamp-project-2022/milestone3/frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/objectSpread\");\nvar _asyncToGenerator = require(\"/Users/aryasastry/bootcamp-project-2022/milestone3/frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/asyncToGenerator\");\nvar _classCallCheck = require(\"/Users/aryasastry/bootcamp-project-2022/milestone3/frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/classCallCheck\");\nvar _createClass = require(\"/Users/aryasastry/bootcamp-project-2022/milestone3/frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/createClass\");\nvar _possibleConstructorReturn = require(\"/Users/aryasastry/bootcamp-project-2022/milestone3/frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/possibleConstructorReturn\");\nvar _getPrototypeOf = require(\"/Users/aryasastry/bootcamp-project-2022/milestone3/frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/getPrototypeOf\");\nvar _inherits = require(\"/Users/aryasastry/bootcamp-project-2022/milestone3/frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/inherits\");\nvar _assertThisInitialized = require(\"/Users/aryasastry/bootcamp-project-2022/milestone3/frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/assertThisInitialized\");\nfunction _regeneratorRuntime() { \"use strict\"; /*! regenerator-runtime -- Copyright (c) 2014-present, Facebook, Inc. -- license (MIT): https://github.com/facebook/regenerator/blob/main/LICENSE */ _regeneratorRuntime = function _regeneratorRuntime() { return exports; }; var exports = {}, Op = Object.prototype, hasOwn = Op.hasOwnProperty, defineProperty = Object.defineProperty || function (obj, key, desc) { obj[key] = desc.value; }, $Symbol = \"function\" == typeof Symbol ? Symbol : {}, iteratorSymbol = $Symbol.iterator || \"@@iterator\", asyncIteratorSymbol = $Symbol.asyncIterator || \"@@asyncIterator\", toStringTagSymbol = $Symbol.toStringTag || \"@@toStringTag\"; function define(obj, key, value) { return Object.defineProperty(obj, key, { value: value, enumerable: !0, configurable: !0, writable: !0 }), obj[key]; } try { define({}, \"\"); } catch (err) { define = function define(obj, key, value) { return obj[key] = value; }; } function wrap(innerFn, outerFn, self, tryLocsList) { var protoGenerator = outerFn && outerFn.prototype instanceof Generator ? outerFn : Generator, generator = Object.create(protoGenerator.prototype), context = new Context(tryLocsList || []); return defineProperty(generator, \"_invoke\", { value: makeInvokeMethod(innerFn, self, context) }), generator; } function tryCatch(fn, obj, arg) { try { return { type: \"normal\", arg: fn.call(obj, arg) }; } catch (err) { return { type: \"throw\", arg: err }; } } exports.wrap = wrap; var ContinueSentinel = {}; function Generator() {} function GeneratorFunction() {} function GeneratorFunctionPrototype() {} var IteratorPrototype = {}; define(IteratorPrototype, iteratorSymbol, function () { return this; }); var getProto = Object.getPrototypeOf, NativeIteratorPrototype = getProto && getProto(getProto(values([]))); NativeIteratorPrototype && NativeIteratorPrototype !== Op && hasOwn.call(NativeIteratorPrototype, iteratorSymbol) && (IteratorPrototype = NativeIteratorPrototype); var Gp = GeneratorFunctionPrototype.prototype = Generator.prototype = Object.create(IteratorPrototype); function defineIteratorMethods(prototype) { [\"next\", \"throw\", \"return\"].forEach(function (method) { define(prototype, method, function (arg) { return this._invoke(method, arg); }); }); } function AsyncIterator(generator, PromiseImpl) { function invoke(method, arg, resolve, reject) { var record = tryCatch(generator[method], generator, arg); if (\"throw\" !== record.type) { var result = record.arg, value = result.value; return value && \"object\" == typeof value && hasOwn.call(value, \"__await\") ? PromiseImpl.resolve(value.__await).then(function (value) { invoke(\"next\", value, resolve, reject); }, function (err) { invoke(\"throw\", err, resolve, reject); }) : PromiseImpl.resolve(value).then(function (unwrapped) { result.value = unwrapped, resolve(result); }, function (error) { return invoke(\"throw\", error, resolve, reject); }); } reject(record.arg); } var previousPromise; defineProperty(this, \"_invoke\", { value: function value(method, arg) { function callInvokeWithMethodAndArg() { return new PromiseImpl(function (resolve, reject) { invoke(method, arg, resolve, reject); }); } return previousPromise = previousPromise ? previousPromise.then(callInvokeWithMethodAndArg, callInvokeWithMethodAndArg) : callInvokeWithMethodAndArg(); } }); } function makeInvokeMethod(innerFn, self, context) { var state = \"suspendedStart\"; return function (method, arg) { if (\"executing\" === state) throw new Error(\"Generator is already running\"); if (\"completed\" === state) { if (\"throw\" === method) throw arg; return doneResult(); } for (context.method = method, context.arg = arg;;) { var delegate = context.delegate; if (delegate) { var delegateResult = maybeInvokeDelegate(delegate, context); if (delegateResult) { if (delegateResult === ContinueSentinel) continue; return delegateResult; } } if (\"next\" === context.method) context.sent = context._sent = context.arg;else if (\"throw\" === context.method) { if (\"suspendedStart\" === state) throw state = \"completed\", context.arg; context.dispatchException(context.arg); } else \"return\" === context.method && context.abrupt(\"return\", context.arg); state = \"executing\"; var record = tryCatch(innerFn, self, context); if (\"normal\" === record.type) { if (state = context.done ? \"completed\" : \"suspendedYield\", record.arg === ContinueSentinel) continue; return { value: record.arg, done: context.done }; } \"throw\" === record.type && (state = \"completed\", context.method = \"throw\", context.arg = record.arg); } }; } function maybeInvokeDelegate(delegate, context) { var methodName = context.method, method = delegate.iterator[methodName]; if (undefined === method) return context.delegate = null, \"throw\" === methodName && delegate.iterator.return && (context.method = \"return\", context.arg = undefined, maybeInvokeDelegate(delegate, context), \"throw\" === context.method) || \"return\" !== methodName && (context.method = \"throw\", context.arg = new TypeError(\"The iterator does not provide a '\" + methodName + \"' method\")), ContinueSentinel; var record = tryCatch(method, delegate.iterator, context.arg); if (\"throw\" === record.type) return context.method = \"throw\", context.arg = record.arg, context.delegate = null, ContinueSentinel; var info = record.arg; return info ? info.done ? (context[delegate.resultName] = info.value, context.next = delegate.nextLoc, \"return\" !== context.method && (context.method = \"next\", context.arg = undefined), context.delegate = null, ContinueSentinel) : info : (context.method = \"throw\", context.arg = new TypeError(\"iterator result is not an object\"), context.delegate = null, ContinueSentinel); } function pushTryEntry(locs) { var entry = { tryLoc: locs[0] }; 1 in locs && (entry.catchLoc = locs[1]), 2 in locs && (entry.finallyLoc = locs[2], entry.afterLoc = locs[3]), this.tryEntries.push(entry); } function resetTryEntry(entry) { var record = entry.completion || {}; record.type = \"normal\", delete record.arg, entry.completion = record; } function Context(tryLocsList) { this.tryEntries = [{ tryLoc: \"root\" }], tryLocsList.forEach(pushTryEntry, this), this.reset(!0); } function values(iterable) { if (iterable) { var iteratorMethod = iterable[iteratorSymbol]; if (iteratorMethod) return iteratorMethod.call(iterable); if (\"function\" == typeof iterable.next) return iterable; if (!isNaN(iterable.length)) { var i = -1, next = function next() { for (; ++i < iterable.length;) { if (hasOwn.call(iterable, i)) return next.value = iterable[i], next.done = !1, next; } return next.value = undefined, next.done = !0, next; }; return next.next = next; } } return { next: doneResult }; } function doneResult() { return { value: undefined, done: !0 }; } return GeneratorFunction.prototype = GeneratorFunctionPrototype, defineProperty(Gp, \"constructor\", { value: GeneratorFunctionPrototype, configurable: !0 }), defineProperty(GeneratorFunctionPrototype, \"constructor\", { value: GeneratorFunction, configurable: !0 }), GeneratorFunction.displayName = define(GeneratorFunctionPrototype, toStringTagSymbol, \"GeneratorFunction\"), exports.isGeneratorFunction = function (genFun) { var ctor = \"function\" == typeof genFun && genFun.constructor; return !!ctor && (ctor === GeneratorFunction || \"GeneratorFunction\" === (ctor.displayName || ctor.name)); }, exports.mark = function (genFun) { return Object.setPrototypeOf ? Object.setPrototypeOf(genFun, GeneratorFunctionPrototype) : (genFun.__proto__ = GeneratorFunctionPrototype, define(genFun, toStringTagSymbol, \"GeneratorFunction\")), genFun.prototype = Object.create(Gp), genFun; }, exports.awrap = function (arg) { return { __await: arg }; }, defineIteratorMethods(AsyncIterator.prototype), define(AsyncIterator.prototype, asyncIteratorSymbol, function () { return this; }), exports.AsyncIterator = AsyncIterator, exports.async = function (innerFn, outerFn, self, tryLocsList, PromiseImpl) { void 0 === PromiseImpl && (PromiseImpl = Promise); var iter = new AsyncIterator(wrap(innerFn, outerFn, self, tryLocsList), PromiseImpl); return exports.isGeneratorFunction(outerFn) ? iter : iter.next().then(function (result) { return result.done ? result.value : iter.next(); }); }, defineIteratorMethods(Gp), define(Gp, toStringTagSymbol, \"Generator\"), define(Gp, iteratorSymbol, function () { return this; }), define(Gp, \"toString\", function () { return \"[object Generator]\"; }), exports.keys = function (val) { var object = Object(val), keys = []; for (var key in object) { keys.push(key); } return keys.reverse(), function next() { for (; keys.length;) { var key = keys.pop(); if (key in object) return next.value = key, next.done = !1, next; } return next.done = !0, next; }; }, exports.values = values, Context.prototype = { constructor: Context, reset: function reset(skipTempReset) { if (this.prev = 0, this.next = 0, this.sent = this._sent = undefined, this.done = !1, this.delegate = null, this.method = \"next\", this.arg = undefined, this.tryEntries.forEach(resetTryEntry), !skipTempReset) for (var name in this) { \"t\" === name.charAt(0) && hasOwn.call(this, name) && !isNaN(+name.slice(1)) && (this[name] = undefined); } }, stop: function stop() { this.done = !0; var rootRecord = this.tryEntries[0].completion; if (\"throw\" === rootRecord.type) throw rootRecord.arg; return this.rval; }, dispatchException: function dispatchException(exception) { if (this.done) throw exception; var context = this; function handle(loc, caught) { return record.type = \"throw\", record.arg = exception, context.next = loc, caught && (context.method = \"next\", context.arg = undefined), !!caught; } for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i], record = entry.completion; if (\"root\" === entry.tryLoc) return handle(\"end\"); if (entry.tryLoc <= this.prev) { var hasCatch = hasOwn.call(entry, \"catchLoc\"), hasFinally = hasOwn.call(entry, \"finallyLoc\"); if (hasCatch && hasFinally) { if (this.prev < entry.catchLoc) return handle(entry.catchLoc, !0); if (this.prev < entry.finallyLoc) return handle(entry.finallyLoc); } else if (hasCatch) { if (this.prev < entry.catchLoc) return handle(entry.catchLoc, !0); } else { if (!hasFinally) throw new Error(\"try statement without catch or finally\"); if (this.prev < entry.finallyLoc) return handle(entry.finallyLoc); } } } }, abrupt: function abrupt(type, arg) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.tryLoc <= this.prev && hasOwn.call(entry, \"finallyLoc\") && this.prev < entry.finallyLoc) { var finallyEntry = entry; break; } } finallyEntry && (\"break\" === type || \"continue\" === type) && finallyEntry.tryLoc <= arg && arg <= finallyEntry.finallyLoc && (finallyEntry = null); var record = finallyEntry ? finallyEntry.completion : {}; return record.type = type, record.arg = arg, finallyEntry ? (this.method = \"next\", this.next = finallyEntry.finallyLoc, ContinueSentinel) : this.complete(record); }, complete: function complete(record, afterLoc) { if (\"throw\" === record.type) throw record.arg; return \"break\" === record.type || \"continue\" === record.type ? this.next = record.arg : \"return\" === record.type ? (this.rval = this.arg = record.arg, this.method = \"return\", this.next = \"end\") : \"normal\" === record.type && afterLoc && (this.next = afterLoc), ContinueSentinel; }, finish: function finish(finallyLoc) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.finallyLoc === finallyLoc) return this.complete(entry.completion, entry.afterLoc), resetTryEntry(entry), ContinueSentinel; } }, catch: function _catch(tryLoc) { for (var i = this.tryEntries.length - 1; i >= 0; --i) { var entry = this.tryEntries[i]; if (entry.tryLoc === tryLoc) { var record = entry.completion; if (\"throw\" === record.type) { var thrown = record.arg; resetTryEntry(entry); } return thrown; } } throw new Error(\"illegal catch attempt\"); }, delegateYield: function delegateYield(iterable, resultName, nextLoc) { return this.delegate = { iterator: values(iterable), resultName: resultName, nextLoc: nextLoc }, \"next\" === this.method && (this.arg = undefined), ContinueSentinel; } }, exports; }\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.GridFSBucketWriteStream = void 0;\nvar stream_1 = require(\"stream\");\nvar bson_1 = require(\"../bson\");\nvar error_1 = require(\"../error\");\nvar write_concern_1 = require(\"./../write_concern\");\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n * @public\n */\nvar GridFSBucketWriteStream = /*#__PURE__*/function (_stream_1$Writable) {\n  _inherits(GridFSBucketWriteStream, _stream_1$Writable);\n  /**\n   * @param bucket - Handle for this stream's corresponding bucket\n   * @param filename - The value of the 'filename' key in the files doc\n   * @param options - Optional settings.\n   * @internal\n   */\n  function GridFSBucketWriteStream(bucket, filename, options) {\n    var _this;\n    _classCallCheck(this, GridFSBucketWriteStream);\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(GridFSBucketWriteStream).call(this));\n    /**\n     * The document containing information about the inserted file.\n     * This property is defined _after_ the finish event has been emitted.\n     * It will remain `null` if an error occurs.\n     *\n     * @example\n     * ```ts\n     * fs.createReadStream('file.txt')\n     *   .pipe(bucket.openUploadStream('file.txt'))\n     *   .on('finish', function () {\n     *     console.log(this.gridFSFile)\n     *   })\n     * ```\n     */\n    _this.gridFSFile = null;\n    options = options ?? {};\n    _this.bucket = bucket;\n    _this.chunks = bucket.s._chunksCollection;\n    _this.filename = filename;\n    _this.files = bucket.s._filesCollection;\n    _this.options = options;\n    _this.writeConcern = write_concern_1.WriteConcern.fromOptions(options) || bucket.s.options.writeConcern;\n    // Signals the write is all done\n    _this.done = false;\n    _this.id = options.id ? options.id : new bson_1.ObjectId();\n    // properly inherit the default chunksize from parent\n    _this.chunkSizeBytes = options.chunkSizeBytes || _this.bucket.s.options.chunkSizeBytes;\n    _this.bufToStore = Buffer.alloc(_this.chunkSizeBytes);\n    _this.length = 0;\n    _this.n = 0;\n    _this.pos = 0;\n    _this.state = {\n      streamEnd: false,\n      outstandingRequests: 0,\n      errored: false,\n      aborted: false\n    };\n    if (!_this.bucket.s.calledOpenUploadStream) {\n      _this.bucket.s.calledOpenUploadStream = true;\n      checkIndexes(_assertThisInitialized(_assertThisInitialized(_this))).then(function () {\n        _this.bucket.s.checkedIndexes = true;\n        _this.bucket.emit('index');\n      }, function () {\n        return null;\n      });\n    }\n    return _this;\n  }\n  /**\n   * @internal\n   *\n   * The stream is considered constructed when the indexes are done being created\n   */\n  _createClass(GridFSBucketWriteStream, [{\n    key: \"_construct\",\n    value: function _construct(callback) {\n      if (this.bucket.s.checkedIndexes) {\n        return process.nextTick(callback);\n      }\n      this.bucket.once('index', callback);\n    }\n    /**\n     * @internal\n     * Write a buffer to the stream.\n     *\n     * @param chunk - Buffer to write\n     * @param encoding - Optional encoding for the buffer\n     * @param callback - Function to call when the chunk was added to the buffer, or if the entire chunk was persisted to MongoDB if this chunk caused a flush.\n     */\n  }, {\n    key: \"_write\",\n    value: function _write(chunk, encoding, callback) {\n      doWrite(this, chunk, encoding, callback);\n    } /** @internal */\n  }, {\n    key: \"_final\",\n    value: function _final(callback) {\n      if (this.state.streamEnd) {\n        return process.nextTick(callback);\n      }\n      this.state.streamEnd = true;\n      writeRemnant(this, callback);\n    }\n    /**\n     * Places this write stream into an aborted state (all future writes fail)\n     * and deletes all chunks that have already been written.\n     */\n  }, {\n    key: \"abort\",\n    value: function () {\n      var _abort = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee() {\n        return _regeneratorRuntime().wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                if (!this.state.streamEnd) {\n                  _context.next = 2;\n                  break;\n                }\n                throw new error_1.MongoAPIError('Cannot abort a stream that has already completed');\n              case 2:\n                if (!this.state.aborted) {\n                  _context.next = 4;\n                  break;\n                }\n                throw new error_1.MongoAPIError('Cannot call abort() on a stream twice');\n              case 4:\n                this.state.aborted = true;\n                _context.next = 7;\n                return this.chunks.deleteMany({\n                  files_id: this.id\n                });\n              case 7:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this);\n      }));\n      function abort() {\n        return _abort.apply(this, arguments);\n      }\n      return abort;\n    }()\n  }]);\n  return GridFSBucketWriteStream;\n}(stream_1.Writable);\nexports.GridFSBucketWriteStream = GridFSBucketWriteStream;\nfunction handleError(stream, error, callback) {\n  if (stream.state.errored) {\n    process.nextTick(callback);\n    return;\n  }\n  stream.state.errored = true;\n  process.nextTick(callback, error);\n}\nfunction createChunkDoc(filesId, n, data) {\n  return {\n    _id: new bson_1.ObjectId(),\n    files_id: filesId,\n    n: n,\n    data: data\n  };\n}\nfunction checkChunksIndex(_x) {\n  return _checkChunksIndex.apply(this, arguments);\n}\nfunction _checkChunksIndex() {\n  _checkChunksIndex = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2(stream) {\n    var index, indexes, hasChunksIndex;\n    return _regeneratorRuntime().wrap(function _callee2$(_context2) {\n      while (1) {\n        switch (_context2.prev = _context2.next) {\n          case 0:\n            index = {\n              files_id: 1,\n              n: 1\n            };\n            _context2.prev = 1;\n            _context2.next = 4;\n            return stream.chunks.listIndexes().toArray();\n          case 4:\n            indexes = _context2.sent;\n            _context2.next = 14;\n            break;\n          case 7:\n            _context2.prev = 7;\n            _context2.t0 = _context2[\"catch\"](1);\n            if (!(_context2.t0 instanceof error_1.MongoError && _context2.t0.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound)) {\n              _context2.next = 13;\n              break;\n            }\n            indexes = [];\n            _context2.next = 14;\n            break;\n          case 13:\n            throw _context2.t0;\n          case 14:\n            hasChunksIndex = !!indexes.find(function (index) {\n              var keys = Object.keys(index.key);\n              if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n                return true;\n              }\n              return false;\n            });\n            if (hasChunksIndex) {\n              _context2.next = 18;\n              break;\n            }\n            _context2.next = 18;\n            return stream.chunks.createIndex(index, _objectSpread({}, stream.writeConcern, {\n              background: true,\n              unique: true\n            }));\n          case 18:\n          case \"end\":\n            return _context2.stop();\n        }\n      }\n    }, _callee2, null, [[1, 7]]);\n  }));\n  return _checkChunksIndex.apply(this, arguments);\n}\nfunction checkDone(stream, callback) {\n  if (stream.done) {\n    return process.nextTick(callback);\n  }\n  if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\n    // Set done so we do not trigger duplicate createFilesDoc\n    stream.done = true;\n    // Create a new files doc\n    var gridFSFile = createFilesDoc(stream.id, stream.length, stream.chunkSizeBytes, stream.filename, stream.options.contentType, stream.options.aliases, stream.options.metadata);\n    if (isAborted(stream, callback)) {\n      return;\n    }\n    stream.files.insertOne(gridFSFile, {\n      writeConcern: stream.writeConcern\n    }).then(function () {\n      stream.gridFSFile = gridFSFile;\n      callback();\n    }, function (error) {\n      return handleError(stream, error, callback);\n    });\n    return;\n  }\n  process.nextTick(callback);\n}\nfunction checkIndexes(_x2) {\n  return _checkIndexes.apply(this, arguments);\n}\nfunction _checkIndexes() {\n  _checkIndexes = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee3(stream) {\n    var doc, index, indexes, hasFileIndex;\n    return _regeneratorRuntime().wrap(function _callee3$(_context3) {\n      while (1) {\n        switch (_context3.prev = _context3.next) {\n          case 0:\n            _context3.next = 2;\n            return stream.files.findOne({}, {\n              projection: {\n                _id: 1\n              }\n            });\n          case 2:\n            doc = _context3.sent;\n            if (!(doc != null)) {\n              _context3.next = 5;\n              break;\n            }\n            return _context3.abrupt(\"return\");\n          case 5:\n            index = {\n              filename: 1,\n              uploadDate: 1\n            };\n            _context3.prev = 6;\n            _context3.next = 9;\n            return stream.files.listIndexes().toArray();\n          case 9:\n            indexes = _context3.sent;\n            _context3.next = 19;\n            break;\n          case 12:\n            _context3.prev = 12;\n            _context3.t0 = _context3[\"catch\"](6);\n            if (!(_context3.t0 instanceof error_1.MongoError && _context3.t0.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound)) {\n              _context3.next = 18;\n              break;\n            }\n            indexes = [];\n            _context3.next = 19;\n            break;\n          case 18:\n            throw _context3.t0;\n          case 19:\n            hasFileIndex = !!indexes.find(function (index) {\n              var keys = Object.keys(index.key);\n              if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n                return true;\n              }\n              return false;\n            });\n            if (hasFileIndex) {\n              _context3.next = 23;\n              break;\n            }\n            _context3.next = 23;\n            return stream.files.createIndex(index, {\n              background: false\n            });\n          case 23:\n            _context3.next = 25;\n            return checkChunksIndex(stream);\n          case 25:\n          case \"end\":\n            return _context3.stop();\n        }\n      }\n    }, _callee3, null, [[6, 12]]);\n  }));\n  return _checkIndexes.apply(this, arguments);\n}\nfunction createFilesDoc(_id, length, chunkSize, filename, contentType, aliases, metadata) {\n  var ret = {\n    _id: _id,\n    length: length,\n    chunkSize: chunkSize,\n    uploadDate: new Date(),\n    filename: filename\n  };\n  if (contentType) {\n    ret.contentType = contentType;\n  }\n  if (aliases) {\n    ret.aliases = aliases;\n  }\n  if (metadata) {\n    ret.metadata = metadata;\n  }\n  return ret;\n}\nfunction doWrite(stream, chunk, encoding, callback) {\n  if (isAborted(stream, callback)) {\n    return;\n  }\n  var inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n  stream.length += inputBuf.length;\n  // Input is small enough to fit in our buffer\n  if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\n    inputBuf.copy(stream.bufToStore, stream.pos);\n    stream.pos += inputBuf.length;\n    process.nextTick(callback);\n    return;\n  }\n  // Otherwise, buffer is too big for current chunk, so we need to flush\n  // to MongoDB.\n  var inputBufRemaining = inputBuf.length;\n  var spaceRemaining = stream.chunkSizeBytes - stream.pos;\n  var numToCopy = Math.min(spaceRemaining, inputBuf.length);\n  var outstandingRequests = 0;\n  while (inputBufRemaining > 0) {\n    var inputBufPos = inputBuf.length - inputBufRemaining;\n    inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\n    stream.pos += numToCopy;\n    spaceRemaining -= numToCopy;\n    var doc = void 0;\n    if (spaceRemaining === 0) {\n      doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\n      ++stream.state.outstandingRequests;\n      ++outstandingRequests;\n      if (isAborted(stream, callback)) {\n        return;\n      }\n      stream.chunks.insertOne(doc, {\n        writeConcern: stream.writeConcern\n      }).then(function () {\n        --stream.state.outstandingRequests;\n        --outstandingRequests;\n        if (!outstandingRequests) {\n          checkDone(stream, callback);\n        }\n      }, function (error) {\n        return handleError(stream, error, callback);\n      });\n      spaceRemaining = stream.chunkSizeBytes;\n      stream.pos = 0;\n      ++stream.n;\n    }\n    inputBufRemaining -= numToCopy;\n    numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n  }\n}\nfunction writeRemnant(stream, callback) {\n  // Buffer is empty, so don't bother to insert\n  if (stream.pos === 0) {\n    return checkDone(stream, callback);\n  }\n  ++stream.state.outstandingRequests;\n  // Create a new buffer to make sure the buffer isn't bigger than it needs\n  // to be.\n  var remnant = Buffer.alloc(stream.pos);\n  stream.bufToStore.copy(remnant, 0, 0, stream.pos);\n  var doc = createChunkDoc(stream.id, stream.n, remnant);\n  // If the stream was aborted, do not write remnant\n  if (isAborted(stream, callback)) {\n    return;\n  }\n  stream.chunks.insertOne(doc, {\n    writeConcern: stream.writeConcern\n  }).then(function () {\n    --stream.state.outstandingRequests;\n    checkDone(stream, callback);\n  }, function (error) {\n    return handleError(stream, error, callback);\n  });\n}\nfunction isAborted(stream, callback) {\n  if (stream.state.aborted) {\n    process.nextTick(callback, new error_1.MongoAPIError('Stream has been aborted'));\n    return true;\n  }\n  return false;\n}","map":null,"metadata":{},"sourceType":"script"}